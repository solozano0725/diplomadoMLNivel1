{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ejercicios_ML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/solozano0725/diplomadoMLNivel1/blob/main/Ejercicios_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWO838CAzjeL"
      },
      "source": [
        "# **Ejercicio 1**: Predicción de precios de diamantes\n",
        "\n",
        "Este conjunto de datos contiene información de diferentes diamantes. Las características del conjunto de datos son:\n",
        "\n",
        "* **price:** Precio (US) del diamante\n",
        "* **carat** Peso del diamante\n",
        "* **cut**: Calidad del corte (Fair, Good, Very Good, Premium, Ideal)\n",
        "* **color**: Color del diamante, desde J (peor) hasta D (mejor)\n",
        "* **clarity**: Una medida de claridad del diamante (I1 (peor), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (mejor))\n",
        "* **x**: Longitud en mm \n",
        "* **y**: Ancho en mm \n",
        "* **z**: Profundidad en mm \n",
        "* **depth**: Porcentaje de profundidad total $\\frac{2z}{x + y}$\n",
        "* **table**: Ancho de la parte superior del diamante en relación con el punto más ancho"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PfKjEUXzo__"
      },
      "source": [
        "<p><img alt=\"Colaboratory logo\" height=\"540px\" src=\"https://i.imgur.com/FPgBl0y.jpg\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LKMBZTKzrBp"
      },
      "source": [
        "* Importe el conjunto de datos `diamonds.csv` del [repositorio](https://github.com/diplomadomludea/nivel_1) del curso y obtenga una primera descripción del mismo. ¿Hay valores faltantes en el conjunto de datos? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0FsFA_UzRHM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOQu9ia75cRt"
      },
      "source": [
        "para ver la solución haga doble click aquí\n",
        "\n",
        "<!-- \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve \n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, PolynomialFeatures\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "diamonds = pd.read_csv(\"https://raw.githubusercontent.com/diplomadomludea/nivel_1/master/data/diamonds.csv\", index_col=[0])\n",
        "\n",
        "diamonds.head()\n",
        "\n",
        "diamonds.info()\n",
        "\n",
        "Observamos de esta información que el conjunto de datos no contiene valores faltantes\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSq1OByn46l5"
      },
      "source": [
        "* Defina una función `plot_cat_feature` que tome como argumento una característica categórica del conjunto de datos y que realice un gráfico de conteo y un gráfico de caja para ver la relación de la variable categórica con el precio. ¿Identifica valores aislados en el gráfico de caja? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFOhTw_F49eM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyU0jt145dQn"
      },
      "source": [
        "para ver la solución haga doble click aquí\n",
        "\n",
        "<!-- \n",
        "def plot_cat_feature(feature):\n",
        "  fig, ax = plt.subplots(1,2, figsize=(15,7))\n",
        "\n",
        "  sns.countplot(data=diamonds, x=feature, ax=ax[0])\n",
        "  sns.boxplot(data=diamonds, x=feature, y=\"price\", ax=ax[1]);\n",
        "\n",
        "plot_cat_feature(\"cut\")\n",
        "plot_cat_feature(\"clarity\")\n",
        "plot_cat_feature(\"color\")\n",
        "\n",
        "Las tres características \"clarity\", \"cut\" y \"color\" tienen un gran número de valores aislados, por lo que la mejor estrategia tal vez sea mantener estos datos.\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V81nR8Bc4_hf"
      },
      "source": [
        "* Defina una función `plot_num_feature` que tome como argumento una característica numérica del conjunto de datos y muestre la distribución de la variable y un gráfico de dispersión para ver su relación con el precio. ¿Identifica valores aislados?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4Vvs4YG4_6b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geLaQC5c5eTc"
      },
      "source": [
        "para ver la solución haga doble click aquí\n",
        "\n",
        "<!-- \n",
        "def plot_num_feature(feature):\n",
        "  fig, ax = plt.subplots(1,2, figsize=(15,7))\n",
        "\n",
        "  sns.histplot(data=diamonds, x=feature, kde=\"True\", ax=ax[0])\n",
        "  sns.scatterplot(data=diamonds, x=feature, y=\"price\", ax=ax[1]);\n",
        "\n",
        "plot_num_feature(\"carat\")\n",
        "plot_num_feature(\"depth\")\n",
        "plot_num_feature(\"table\")\n",
        "plot_num_feature(\"x\")\n",
        "plot_num_feature(\"y\")\n",
        "plot_num_feature(\"z\")\n",
        "\n",
        "Las variables `depth`, `table`, `x`, `y` y `z` contienen valores aislados que pueden ser eliminados:\n",
        "\n",
        "diamonds = diamonds.loc[diamonds.depth.between(45, 75)]\n",
        "diamonds = diamonds.loc[diamonds.table.between(45, 80)]\n",
        "diamonds = diamonds.loc[diamonds.x != 0]\n",
        "diamonds = diamonds.loc[diamonds.y.between(0.1,20)]\n",
        "diamonds = diamonds.loc[diamonds.z.between(2,10)]\n",
        "\n",
        "visualicemos de nuevo las distribuciones:\n",
        "\n",
        "plot_num_feature(\"depth\")\n",
        "plot_num_feature(\"table\")\n",
        "plot_num_feature(\"x\")\n",
        "plot_num_feature(\"y\")\n",
        "plot_num_feature(\"z\")\n",
        "\n",
        "¡Mucho mejor!\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfhltNuz5Fs4"
      },
      "source": [
        "* Visualice la correlación de las características con la variable objetivo ¿Qué características están más correlacionadas? ¿Qué características están menos correlacionadas? ¿Qué podría hacer en ambos casos?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y5W9PzJ5F96"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKzWVxcx5fAl"
      },
      "source": [
        "para ver la solución haga doble click aquí\n",
        "\n",
        "<!-- \n",
        "Utilizamos la correlación de `spearman` ya que las características no tienen distribuciones normales\n",
        "\n",
        "# correlation\n",
        "corr = diamonds.corr(method=\"spearman\")\n",
        "\n",
        "plt.figure(figsize=(11,8))\n",
        "sns.heatmap(corr, vmin=-1, vmax=1, cmap=\"coolwarm\", annot=True);\n",
        "\n",
        "Vemos que Las características `depth` y `table` están muy poco correlacionadas con la variable objetivo. Estas no afectarán significativamente el modelo final (puede experimentar eliminando los datos y manteniéndolos). \n",
        "\n",
        "Las características `x`, `y` y `z` están altamente correlacionadas entre sí, por lo que podríamos construir una única variable que contenga la información de las tres características\n",
        "\n",
        "# volume feature\n",
        "diamonds[\"vol\"] = diamonds.x * diamonds.y * diamonds.z\n",
        "\n",
        "# dropping \"x\",\"y\" and \"z\" features\n",
        "diamonds.drop(columns=[\"x\",\"y\",\"z\"], inplace=True)\n",
        "\n",
        "# volume distribution\n",
        "plot_num_feature(\"vol\")\n",
        "\n",
        "# correlation\n",
        "plt.figure(figsize=(11,8))\n",
        "sns.heatmap(corr, vmin=-1, vmax=1, cmap=\"coolwarm\", annot=True);\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlkfhLWU5JRd"
      },
      "source": [
        "* Defina un preprocesador que realice una estandarización sobre las características numéricas y una codificación de las características categóricas. Evalúe el modelo mediante una validación cruzada y obtenga una curva de aprendizaje para examinar el comportamiento del modelo respecto al número de instancias. ¿Con cuál esquema de codificación se encuentra el mejor resultado? ¿El modelo subajusta o sobreajusta los datos en ambos casos?\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5c7uQPt5Jja"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxghpsy5gGs"
      },
      "source": [
        "para ver la solución haga doble click aquí\n",
        "\n",
        "<!-- \n",
        "# feature matrix and label\n",
        "X = diamonds.drop(columns=\"price\")\n",
        "y = diamonds[\"price\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# numerical and categorical features\n",
        "num_features = X.select_dtypes(exclude=\"object\").columns\n",
        "cat_features = X.select_dtypes(include=\"object\").columns\n",
        "\n",
        "# ORDINAL ENCODING -----------------------------------------\n",
        "preprocessor = make_column_transformer((StandardScaler(), num_features), \n",
        "                                       (OrdinalEncoder(), cat_features))\n",
        "\n",
        "# model building\n",
        "model = make_pipeline(preprocessor, LinearRegression())\n",
        "\n",
        "# cross validation\n",
        "cross_val_score(model, X_train, y_train)\n",
        "\n",
        "Vemos que el modelo es estable y alcanza un puntaje R2 promedio de 0.88.\n",
        "\n",
        "# learning curve\n",
        "N, train_score, val_score = learning_curve(model, X_train, y_train, cv=5, train_sizes=np.linspace(0.1,1,30))\n",
        "\n",
        "fig = plt.figure(figsize=(10,7))\n",
        "plt.plot(N, np.mean(train_score, axis=1), \"b\", label='train score')\n",
        "plt.plot(N, np.mean(val_score, axis=1), \"r\", label='test score')\n",
        "plt.xlabel('training size')\n",
        "plt.ylabel('score')\n",
        "plt.legend();\n",
        "\n",
        "\n",
        "# ONE-HOT ENCODING -----------------------------------------\n",
        "preprocessor = make_column_transformer((StandardScaler(), num_features), \n",
        "                                       (OneHotEncoder(), cat_features))\n",
        "\n",
        "model = make_pipeline(preprocessor, LinearRegression())\n",
        "\n",
        "cross_val_score(model, X_train, y_train)\n",
        "\n",
        "De nuevo, vemos que el modelo es estable y alcanza un puntaje R2 promedio de 0.91\n",
        "\n",
        "N, train_score, val_score = learning_curve(model, X_train, y_train, cv=5, train_sizes=np.linspace(0.1,1,30))\n",
        "\n",
        "# learning curve\n",
        "fig = plt.figure(figsize=(10,7))\n",
        "plt.plot(N, np.mean(train_score, axis=1), \"b\", label='train score')\n",
        "plt.plot(N, np.mean(val_score, axis=1), \"r\", label='test score')\n",
        "plt.xlabel('training size')\n",
        "plt.ylabel('score')\n",
        "plt.legend();\n",
        "\n",
        "La codificación one-hot da mejores resultados y en ambos casos los modelos no presentan subajuste ni sobreajuste de acuerdo a las curvas de aprendizaje\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7yHAzfR5Ms1"
      },
      "source": [
        "* Añada una transformación polinomial al preprocesador (para las características numéricas) y construya modelos de regresión polinomial de grados `[2,3,4,5]`. Para esto, defina una función `poly_reg` que tome como argumento el grado del polinomio y retorne el modelo de regresión polinomial. ¿Mejoran los resultados respecto a la regresión lineal? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEwgfm-f5N5q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDcB8Aza5hAt"
      },
      "source": [
        "para ver la solución haga doble click aquí\n",
        "\n",
        "<!-- \n",
        "def poly_reg(degree):\n",
        "  \"\"\"lineal regression model\"\"\"\n",
        "  num_trans = make_pipeline(StandardScaler(), PolynomialFeatures(degree))\n",
        "\n",
        "  preprocessor = make_column_transformer((num_trans, num_features), \n",
        "                                         (OneHotEncoder(), cat_features))\n",
        "  \n",
        "  return make_pipeline(preprocessor, LinearRegression())\n",
        "\n",
        "for degree in [2,3,4,5]:\n",
        "  model = poly_reg(degree).fit(X_train, y_train)\n",
        "  print(f\"degree: {degree}, test score: {model.score(X_test, y_test)}\")\n",
        "\n",
        "Para un grado tres se obtiene un puntaje de validación de 0.93, lo cual supone una leve mejora respecto a la regresión polinomial\n",
        "\n",
        "# learning curve\n",
        "N, train_score, val_score = learning_curve(poly_reg(3), X_train, y_train, cv=5, train_sizes=np.linspace(0.1,1,30))\n",
        "\n",
        "fig = plt.figure(figsize=(10,7))\n",
        "plt.plot(N, np.mean(train_score, axis=1), \"b\", label='train score')\n",
        "plt.plot(N, np.mean(val_score, axis=1), \"r\", label='test score')\n",
        "plt.xlabel('training size')\n",
        "plt.ylabel('score')\n",
        "plt.legend();\n",
        "\n",
        "De la curva de validación vemos que el modelo está en un punto óptimo de sesgo/varianza\n",
        "\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daud8SJ9DjWH"
      },
      "source": [
        "# **Ejercicio 2:** Detección de spam\n",
        "\n",
        "El conjunto de datos que vamos a utilizar en este ejercicio contiene alrededor de 5572 mensajes de texto (en inglés) etiquetados como *spam* o *no spam* (*ham*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJwOJls5Ecgl"
      },
      "source": [
        "* Importe el conjunto de datos `spam.csv` del repositorio del curso. Los datos deben tener la siguiente forma\n",
        "\n",
        "  ![](https://i.imgur.com/t43Yn2o.png)\n",
        "\n",
        "  Consulte el parámetro `encoding` de la función `pd.read_csv`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsJdgSJDEYnM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFnZrg8bFd3R"
      },
      "source": [
        "para ver la solución haga doble click aquí\n",
        "\n",
        "<!-- \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import plot_roc_curve, plot_confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/diplomadomludea/nivel_1/master/data/spam.csv\", encoding='latin-1', skipinitialspace=True, skiprows=[0], usecols=[0,1], names=[\"target\",\"message\"])\n",
        "\n",
        "data.head()\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qX9wRg6pFgN6"
      },
      "source": [
        "* ¿El conjunto de datos es desbalanceado? Realice un gráfico de barras para visualizar el número de instancias para cada clase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGF29k6ZFt2E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCsb_5NuFuKv"
      },
      "source": [
        "para ver la solución haga doble click aquí\n",
        "\n",
        "<!-- \n",
        "data.target.value_counts()\n",
        "\n",
        "El conjunto de datos es desbalanceado: contiene 4825 instancias de la clase \"ham\" y 747 de la clase \"spam\"\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.countplot(data=data, x=\"target\");\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrwwXstkGCIA"
      },
      "source": [
        "* Construya una nueva característica `length` que contenga el número de palabras por mensaje. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI6UDr_dGd6F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-ZUcF7-GeNc"
      },
      "source": [
        "para ver la solución haga doble click aquí\n",
        "\n",
        "<!-- \n",
        "data['length'] = data.message.str.split().apply(len)\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tHwQQ0WGg6R"
      },
      "source": [
        "* Realice un gráfico de densidad para visualizar la característica `length` distinguiendo las clases por un código de color. ¿Qué acción realizar a partir de la información que se obtiene de esta visualización?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jc53sezGhQ2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQhG5UPsGheu"
      },
      "source": [
        "para ver la solución haga doble click aquí\n",
        "\n",
        "<!-- \n",
        "plt.figure(figsize=(10,7))\n",
        "sns.kdeplot(data=data, x=\"length\", hue=\"target\", shade=True);\n",
        "\n",
        "de aquí podemos ver que las instancias con un número de palabras mayor a 50 no son significativas. Eliminar estas instancias podría mejorar el rendimiento del modelo.\n",
        "\n",
        "data = data.loc[data.length < 50]\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.kdeplot(data=data, x=\"length\", hue=\"target\", shade=True);\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sri41df7Ir0A"
      },
      "source": [
        "* Separe los datos en los conjuntos de entrenamiento y prueba y entrene tres modelos de clasificación utilizando Naive Bayes multinomial, SVM y regresión logística."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnlAL5PJI4Xu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZgh3N2_I4rO"
      },
      "source": [
        "para ver la solución haga doble click aquí\n",
        "\n",
        "<!-- \n",
        "X = data.message\n",
        "y = data.target.replace({\"spam\":1, \"ham\":0})\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "nb_clf = make_pipeline(TfidfVectorizer(), \n",
        "                       MultinomialNB()).fit(X_train, y_train)\n",
        "\n",
        "svm_clf = make_pipeline(TfidfVectorizer(),\n",
        "                        SVC()).fit(X_train, y_train)      \n",
        "\n",
        "lr_clf = make_pipeline(TfidfVectorizer(),\n",
        "                       LogisticRegression()).fit(X_train,y_train)                                           \n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3uwhp-lI5Ot"
      },
      "source": [
        "* Realice una validación cruzada para los tres clasificadores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl6vbB7gJCTF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2kFs3SoJCic"
      },
      "source": [
        "para ver la solución haga doble click aquí\n",
        "\n",
        "<!-- \n",
        "models = [\"Naive Bayes\", \"SVM\", \"Logistic Regression\"]\n",
        "clfs = [nb_clf, svm_clf, lr_clf]\n",
        "\n",
        "for model, clf in zip(models, clfs):\n",
        "  print(f\"{model}: {cross_val_score(clf, X, y, cv=5).mean()}\")\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdDkjal6JgVM"
      },
      "source": [
        "* Obtenga la matriz de confusión para cada clasificador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7E7d3VRJeZN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt9iKw_HJetd"
      },
      "source": [
        "para ver la solución haga doble click aquí\n",
        "\n",
        "<!-- \n",
        "for model, clf in zip(models, clfs):\n",
        "  fig, ax = plt.subplots(figsize=(8, 5))\n",
        "  plot_confusion_matrix(clf, X_test, y_test, values_format=\"d\", cmap=\"Blues\", ax=ax)\n",
        "  ax.grid(None)\n",
        "  ax.set_title(model);\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU6ii3BqJZOD"
      },
      "source": [
        "* Obtenga los puntajes de *precision*, *recall*, y *f score* para los tres clasificadores. Muestre estos resultados en un DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyED2REAJnNt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xovXYXTCJngt"
      },
      "source": [
        "para ver la solución haga doble click aquí\n",
        "\n",
        "<!-- \n",
        "P = []\n",
        "R = []\n",
        "F = []\n",
        "\n",
        "for clf in clfs:\n",
        "  y_pred = clf.predict(X_test)\n",
        "  P.append(precision_score(y_test, y_pred))\n",
        "  R.append(recall_score(y_test, y_pred))\n",
        "  F.append(f1_score(y_test, y_pred))\n",
        "\n",
        "results = {\"Precision\":P,\n",
        "           \"Recall\": R,\n",
        "           \"f score\": F}\n",
        "\n",
        "pd.DataFrame(results, index=models)\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcDbvL7VJtCL"
      },
      "source": [
        "* Obtenga las curvas ROC para cada clasificador con los datos de prueba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXjEZ89XJtpr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itdaCPs5Jt50"
      },
      "source": [
        "para ver la solución haga doble click aquí\n",
        "\n",
        "<!-- \n",
        "fig, ax = plt.subplots(figsize=(12,8))\n",
        "\n",
        "for model, clf in zip(models, clfs):\n",
        "  plot_roc_curve(clf, X_test, y_test, label=model, ax=ax);\n",
        "-->"
      ]
    }
  ]
}